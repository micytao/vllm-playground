# Demo Configuration
# Copy this file and customize for your needs
# Usage: source demo.env && ./scripts/demo_full_workflow.sh

# =============================================================================
# vLLM Server Configuration
# =============================================================================

# Model to use (HuggingFace model ID or local path)
export BASE_MODEL="TinyLlama/TinyLlama-1.1B-Chat-v1.0"
# Other options:
# export BASE_MODEL="facebook/opt-125m"  # Smaller, faster
# export BASE_MODEL="meta-llama/Llama-3.2-1B"  # Requires HF token
# export BASE_MODEL="google/gemma-2-2b"  # Requires HF token

# Server settings
export VLLM_HOST="127.0.0.1"
export VLLM_PORT="8000"

# CPU Mode Settings (for macOS / Linux CPU)
export VLLM_CPU_KVCACHE_SPACE=40  # GB for KV cache
export VLLM_CPU_OMP_THREADS_BIND="auto"  # Thread binding

# HuggingFace Token (for gated models like Llama, Gemma)
# Get your token from: https://huggingface.co/settings/tokens
# export HF_TOKEN="hf_..."

# =============================================================================
# Model Compression Configuration
# =============================================================================

# Output directory for compressed models
export COMPRESSED_MODEL_DIR="./compressed_models"

# Quantization format
# Options: W8A8_INT8, W8A8_FP8, W4A16, W8A16, W4A4
export QUANTIZATION_FORMAT="W8A8_INT8"

# Compression algorithm
# Options: GPTQ, AWQ, PTQ, SmoothQuant, SparseGPT
export ALGORITHM="GPTQ"

# Number of calibration samples (more = better quality, slower)
# Typical values: 128 (fast demo), 512 (good), 1024 (best)
export CALIBRATION_SAMPLES="512"

# Dataset for calibration
export CALIBRATION_DATASET="open_platypus"

# =============================================================================
# Benchmark Configuration
# =============================================================================

# Total number of requests to send
export BENCHMARK_REQUESTS="100"

# Request rate (requests per second)
# 0 = sweep mode (automatic rate discovery)
export BENCHMARK_RATE="5"

# Token sizes
export PROMPT_TOKENS="128"
export OUTPUT_TOKENS="128"

# Rate type: "constant" or "sweep"
export RATE_TYPE="constant"

# =============================================================================
# Environment
# =============================================================================

# Virtual environment path (optional)
export VENV_PATH="$HOME/.venv"

# =============================================================================
# Preset Configurations
# =============================================================================

# Uncomment one of these preset blocks to use it:

# --- QUICK DEMO (Fast, for testing) ---
# export BASE_MODEL="TinyLlama/TinyLlama-1.1B-Chat-v1.0"
# export QUANTIZATION_FORMAT="W8A8_INT8"
# export CALIBRATION_SAMPLES="128"
# export BENCHMARK_REQUESTS="50"

# --- BALANCED (Good quality, reasonable time) ---
# export BASE_MODEL="TinyLlama/TinyLlama-1.1B-Chat-v1.0"
# export QUANTIZATION_FORMAT="W4A16"
# export CALIBRATION_SAMPLES="512"
# export BENCHMARK_REQUESTS="100"

# --- HIGH COMPRESSION (Smallest models) ---
# export BASE_MODEL="TinyLlama/TinyLlama-1.1B-Chat-v1.0"
# export QUANTIZATION_FORMAT="W4A16"
# export ALGORITHM="GPTQ"
# export CALIBRATION_SAMPLES="1024"
# export BENCHMARK_REQUESTS="200"

# --- LOAD TEST (Stress testing) ---
# export BENCHMARK_REQUESTS="1000"
# export BENCHMARK_RATE="20"
# export PROMPT_TOKENS="256"
# export OUTPUT_TOKENS="256"

# =============================================================================
# Usage Examples
# =============================================================================

# 1. Use this config file:
#    source demo.env
#    ./scripts/demo_full_workflow.sh

# 2. Override specific settings:
#    source demo.env
#    BASE_MODEL="facebook/opt-125m" ./scripts/demo_full_workflow.sh

# 3. Run individual components:
#    source demo.env
#    ./scripts/compress_model.sh "$BASE_MODEL" "$COMPRESSED_MODEL_DIR" "$QUANTIZATION_FORMAT" "$ALGORITHM" "$CALIBRATION_SAMPLES"
#    ./scripts/benchmark_guidellm.sh "$BENCHMARK_REQUESTS" "$BENCHMARK_RATE" "$PROMPT_TOKENS" "$OUTPUT_TOKENS"
